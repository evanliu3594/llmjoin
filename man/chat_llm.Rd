% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/commication.R
\name{chat_llm}
\alias{chat_llm}
\title{Send message to LLM server}
\usage{
chat_llm(
  .message,
  .model = "gpt-4.1-mini",
  .temperature = 0,
  .max_tokens = 1000,
  .timeout = 30
)
}
\arguments{
\item{.message}{the message to send.}

\item{.model}{character, LLM model to use. By default gpt-4.1-mini.}

\item{.temperature}{OpenAI style randomness control (0~1), by default 0.1, the larger, the more rigorous.}

\item{.max_tokens}{Max tokens to spend.}

\item{.timeout}{Max seconds to communicate with LLM}
}
\value{
LLM answer, strings
}
\description{
This function send message to LLM model and retrive the result.
}
\examples{
chat_llm("tell a joke.")
}
