% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/network-utils.R
\name{chat_llm}
\alias{chat_llm}
\title{Send message to LLM server}
\usage{
chat_llm(.message, .model = NULL, .temperature = 0.01, .max_tokens = 1000)
}
\arguments{
\item{.message}{the message to send.}

\item{.model}{char, LLM model to use.}

\item{.temperature}{GPT style randomness control (0~1), by default 0.01, the larger, the more rigorous.}

\item{.max_tokens}{max tokens be sent}
}
\value{
LLM answer
}
\description{
This function send message to LLM model and retrive the result.
}
\examples{
chat_llm("tell a joke.")
}
